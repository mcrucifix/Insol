\name{APF1step}

\alias{APF1step}
\alias{ESS}

\title{One step of Liu and West auxiliary particle filter}
\description{Advance the Liu and West particle filter from one observation to the next.}

\usage{
APF1step(plist, oldt = NULL, newt, N, delta = 0.99, Dt = 1,
         resample = c('residual', 'multinomial'),
         propagate = 'propagate', likelihood = 'likelihood',
         verbose = FALSE, ...)

ESS(weight)
}

\arguments{
  \item{plist}{List of particles and weights (see Value)}
  \item{oldt,newt}{Old time and new time (\code{oldt} can be inferred from the \code{time} attribute of \code{plist})}
  \item{N}{Number of new particles required (defaults to same number as previously)}
  \item{delta}{Discount rate}
  \item{Dt}{Time-interval over which discount rate applies}
  \item{resample}{Resampling method for auxiliary step}
  \item{propagate, likelihood}{Required functions (see below), or their names}
  \item{verbose}{Logical, produce verbose output}
  \item{...}{Additional non-stochastic parameters to be passed to \code{propagate} and \code{likelihood}; safest to pass these in as a named vector}
  \item{weight}{Vector of weights, to compute the Effective Sample Size of a collection of particles}
}

\details{The Liu and West algorithm is for sequential updating in the
presence of unknown time-invariant parameters, using the auxiliary
particle approach.  Each particle comprises a \code{state} vector and
a \code{par} vector, as well as a \code{weight} scalar.

The parameters are resampled according to a KDE.  For this reason the
parameters must be transformed so that a Gaussian distribution is a
reasonable approximation.  The dispersion of this is controlled by the
discount rate \code{delta}, which determines the extent to which
individual values are shrunk back towards the sample mean.  Setting
\code{delta = 1} has the effect of sampling directly from the
individual particles; as \code{delta} falls below one (minimimum value
1/3) the particles are smoothed towards a Gaussian.  It is likely that
\code{delta} will need to be tuned for performance, starting low (say,
0.95), and gradually increasing towards 1 as time increases.
\code{delta} adapts to different-sized time-steps; when it is
specified, it is with respect to a given time-interval, \code{Dt}.

\code{APF1step} requires functions \code{propagate(state, par, oldt,
newt, stochastic, MOREPARS)} and \code{likelihood(time, state, par,
MOREPARS)}.  The first of these takes a particle with state
\code{state} and parameters \code{par} from \code{oldt} to
\code{newt}; if \code{stochastic = FALSE} then this propogation is
according to the mean, mode, or other central measure, otherwise it is
stochastic.  \code{likelihood} computes the likelihood at time
\code{time}.  Both functions will be passed the \code{...} argument,
which should correspond to the \code{MOREPARS} arguments (see
example).

If \code{propagate} returns a vector with an \code{extra} attribute,
then these values are returned in a matrix, matching \code{state} and
\code{pars}.

There is a resampling step.  Liu and West suggest multinomial
resampling, but the default here is residual resampling, which is less
variable.

}

\value{A new set of particles, ie a list with
  \item{state}{Matrix with \code{N} rows;}
  \item{par}{Matrix with \code{N} rows;}
  \item{weight}{Vector of \code{N} weights, normalised;}
  \item{extra}{(Optional) Additional returned values (see above).}
This list has two additional attributes: \code{time}, which is the
value of \code{newt}, and \code{ct}, which is the mean of the
unnormalised weights at time \code{newt}.  If Ct is the marginal
density at time t, then Ct = ct * ct-1 * ... c1.}

\references{

J. Liu and M. West, 2001, 'Combined parameter and state
estimation in simulation-based filtering', pp 197-217 in A. Doucet,
N. de Freitas and N. Gordan (Eds), Sequential Monte Carlo in Practice,
New York: Springer.

J. Liu, 2001, Monte Carlo Methods in Science, New York: Springer. [Not the same Liu!]}

\author{Jonathan Rougier}

\examples{
## simple AR1 model with uncertain coefficients, par = c(mu,
## logit(rho), log(w)), and non-stochastic parameter sdv, which plays
## the role of MOREPARS (see above)

logit <- function(x) log(x / (1 - x))
ilogit <- function(y) exp(y) / (1 + exp(y))

## example of returning additional values (not very interesting
## in this case

propagate <- function(state, par, oldt, newt, stochastic = TRUE, sdv)
{
  ## sdv is ignored here
  for (i in (oldt + 1):newt) {
    state <- par['mu'] + ilogit(par['rho']) * state
    z <- if (stochastic)
      rnorm(1, mean = 0, sd = exp(par['w'])) 
    else 0
    state <- state + z
  }
  robj <- state
  attr(robj, 'extra') <- c(z = z)
  robj
}

## the likelihood function must return NA if there is no observation
## at 'time'

likelihood <- function(time, state, par, sdv)
{
  ## sdv will be used here
  dnorm(obs[time], mean = state, sd = sdv)
}

## simulate real data, not equally-spaced

musd <- 1
shape <- c(1.5, 1.0)
wgam <- 5
  
par <- c(mu = rnorm(1, mean = 0, sd = musd),
         rho = rbeta(1, shape1 = shape[1], shape2 = shape[2]),
         w = rgamma(1, shape = wgam, rate = wgam))

T <- 200 # make this longer to see convergence
state <- rep(NA, T)

state[1] <- rnorm(1,
                  mean = par['mu'] / (1 - par['rho']),
                  sd = par['w'] / sqrt(1 - par['rho']^2))
for (tt in 2:T)
  state[tt] <- propagate(state[tt - 1],
                        par = c(par['mu'], logit(par['rho']), log(par['w'])),
                        oldt = tt - 1, newt = tt)

sdv <- 1.0  
obs <- rep(NA, T)
tmp <- sample(2:T, round(T / 5)) # roughly an obs every 5 time-steps
obs[tmp] <- state[tmp] + rnorm(length(tmp), mean = 0, sd = sdv)

## Initial values of the particles

N <- 2000 # make this bigger for more accurate result

initmu <- rnorm(N, mean = 0, sd = musd)
initrho <- rbeta(N, shape1 = shape[1], shape2 = shape[2])
initw <- rgamma(N, shape = wgam, rate = wgam)
    
particles <- list(state = matrix(
                    rnorm(N,
                          mean = initmu / (1 - initrho),
                          sd = initw / sqrt(1 - initrho^2))),
                  par = cbind(mu = initmu,
                              rho = logit(initrho),
                              w = log(initw)),
                  weight = rep(1/N, N))
attr(particles, 'lnCt') <- 0

## Now run the filter, nb effect of uneven time-steps

times <- c(1, which(!is.na(obs)))
plist <- vector('list', length(times))
plist[[1]] <- particles
  
for (i in seq(along = times)[-1]) {

  tmp <- plist[[i - 1]]

  ess <- ESS(tmp$weight)
  cat(sprintf('\tESS = \%.0f (\%.0f\%\%)\n', ess, 100 * ess / N))

  plist[[i]] <- APF1step(tmp, oldt = times[i - 1], newt = times[i],
                         N = N, delta = 0.95, verbose = TRUE, sdv = sdv)
}

## show this as a picture.  The weebox function is included in the package.

mfrow <- par(mfrow = c(3, 2))$mfrow

## true values, observations, and mean state

tmp <- c(state, unlist(lapply(plist, function(li) li$state)))
ylim <- quantile(tmp, c(0.025, 0.975))
plot(1:T, state, type = 'l', xlim = c(1, T), ylim = ylim,
     xlab = '', ylab = '', main = 'State', col = 'blue')
points(times, obs[times], pch = 16, col = 'red')
means <- sapply(plist, function(li) sum(li$weight * li$state) /
sum(li$weight))
points(times, means, type = 'b', lwd = 2, pch = 16)

## evolving parameter distributions, with true values

for (nm in colnames(plist[[1]]$par)) {

  tmp <- lapply(plist, function(li) li$par[, nm])
  if (nm == 'rho')
    tmp <- lapply(tmp, function(li) ilogit(li))
  if (nm == 'w')
    tmp <- lapply(tmp, function(li) exp(li))
    
  plot(1:T, rep(0, T), type = 'n',
       ylim = range(par[nm], unlist(tmp)),
       xlab = '', ylab = '', main = sprintf('Parameter: \%s', nm))
  abline(h = par[nm], col = 'blue', lwd = 2)
  for (i in seq(along = times))
    weebox(tmp[[i]], plist[[i]]$weight, at = times[i], width = 2)
}

## evolving log marginal likelihood

lnCt <- sapply(plist, function(li) attr(li, 'lnCt'))
plot(times, cumsum(lnCt), type = 'b', pch = 16,
  xlim = c(1, T),
  xlab = '', ylab = '', main = 'Marginal likelihood (log)')

par(mfrow = mfrow)
}

\keyword{misc}
